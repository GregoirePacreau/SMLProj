{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polarity prediction on movie reviews, comparaison of parameters and learning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "(scikit-learn for learning, nltk for text processing and pandas for data reprensentations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning methods\n",
    "To classify a vector of numbers, we used :\n",
    "\n",
    "- Linear regression\n",
    "- MultinomialNM\n",
    "- \n",
    "- \n",
    "\n",
    "## Text representations\n",
    "We tried different representations of data to see how it influences the learning :\n",
    "- Bag-of-words\n",
    "- n-grams\n",
    "- Term frequency (bag-of-words normalized)\n",
    "- Term frequency times inverse document frequency "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from scikitplot.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the datasets\n",
    "(We used the small dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>neg</td>\n",
       "      <td>the summer of 00' wasn't a very good one for d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>neg</td>\n",
       "      <td>ever since wargames , the first real computer ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>pos</td>\n",
       "      <td>three things i learned from \" being john malko...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>neg</td>\n",
       "      <td>a friend invites you to a movie . \\nthis film ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>neg</td>\n",
       "      <td>and just when you thought joblo was getting a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  label_num\n",
       "1355   neg  the summer of 00' wasn't a very good one for d...          0\n",
       "1115   neg  ever since wargames , the first real computer ...          0\n",
       "672    pos  three things i learned from \" being john malko...          1\n",
       "1921   neg  a friend invites you to a movie . \\nthis film ...          0\n",
       "1950   neg  and just when you thought joblo was getting a ...          0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all files path\n",
    "posFiles = glob('review_polarity/txt_sentoken/pos/*')\n",
    "negFiles = glob('review_polarity/txt_sentoken/neg/*')\n",
    "# Read text files\n",
    "posReviews = np.array([open(f).read() for f in posFiles])\n",
    "negReviews = np.array([open(f).read() for f in negFiles])\n",
    "# Use pandas to label, mix the data and print a sample\n",
    "polarity_files_df = pd.DataFrame({'pos':posReviews,'neg':negReviews})\n",
    "polarity_files_df = pd.melt(polarity_files_df, value_vars=['pos','neg'],value_name=\"text\",var_name=\"label\")\n",
    "polarity_files_df[\"label_num\"] = polarity_files_df.label.map({\"neg\":0, \"pos\":1})\n",
    "polarity_files_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700,)\n",
      "(300,)\n",
      "(1700,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "# Split and shuffle the data (15% for train and 75% for tests)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(polarity_files_df.text, polarity_files_df.label_num, test_size=0.15, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.81      0.81      0.81       151\n",
      "         neg       0.81      0.81      0.81       149\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       300\n",
      "   macro avg       0.81      0.81      0.81       300\n",
      "weighted avg       0.81      0.81      0.81       300\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f13fb71c7f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove English stop words\n",
    "# Include 1-grams and 2-grams (if 3-grams : seems not better because of the length of the vector)\n",
    "# Ignore terms that appear in more than 60% of the documents\n",
    "# (intuitively meaningful, at 60% of word frequency in english, we still find words like \"uh\" or a lot of words unnecessary for the learning) \n",
    "# Only keep terms that appear in at least 2 documents\n",
    "\n",
    "# Note: Removing \"stop-words\" can lead in information loss\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range =(1,2), max_df =0.7, min_df=2)),\n",
    "                     ('nb', MultinomialNB()),\n",
    "                    ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "y_pred = text_clf.predict(X_test)\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "# à vérifier : pos et neg sont biens les pos et neg\n",
    "print(metrics.classification_report(y_test, y_pred,\n",
    "    target_names=[\"pos\",\"neg\"]))\n",
    "metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, normalize=True, title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=0.7, max_features=None, min_df=2,\n",
       "           ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "           strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=None, vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       " 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=0.7, max_features=None, min_df=2,\n",
       "         ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=None, vocabulary=None),\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'nb': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 0.7,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 2,\n",
       " 'vect__ngram_range': (1, 3),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': 'english',\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': None,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'nb__alpha': 1.0,\n",
       " 'nb__class_prior': None,\n",
       " 'nb__fit_prior': True}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test a range of hyperparameters\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range =(1,3), max_df =0.7, min_df=2)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('nb', MultinomialNB()),\n",
    "                    ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)  \n",
    "text_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#TO ADAPT depending on what text_clf.get_params() displays\n",
    "#how did we look for a good parameter alpha : try with 1e-3 and 1e-2 : 1e-2 is the best so we tried with 1e0 and 1e-1 and 1e-2 : 1e-1 is the best one\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'nb__alpha': (1e-2, 1e-1),\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82835820895522383"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "y_pred = gs_clf.predict(X_test)\n",
    "\n",
    "gs_clf.best_score_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb__alpha: 0.1\n",
      "tfidf__use_idf: False\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.7, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        ...False,\n",
       "         use_idf=False)), ('nb', MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_estimator_.get_params()[\"nb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.90705363,  2.97942503,  0.81350295,  3.52606408,  0.84179568,\n",
       "         3.05628093,  0.86787113,  2.99055672,  0.8450772 ,  2.92341105,\n",
       "         0.79071728,  2.67280912]),\n",
       " 'mean_score_time': array([ 0.36827596,  0.56174795,  0.35869686,  0.54121161,  0.4139332 ,\n",
       "         0.64748732,  0.40891202,  0.57405368,  0.3593332 ,  0.57712452,\n",
       "         0.34732358,  0.47334862]),\n",
       " 'mean_test_score': array([ 0.80074627,  0.79328358,  0.82835821,  0.82014925,  0.77835821,\n",
       "         0.77537313,  0.80149254,  0.79626866,  0.76119403,  0.76343284,\n",
       "         0.78283582,  0.77835821]),\n",
       " 'mean_train_score': array([ 0.99291072,  0.9981353 ,  0.98656841,  0.99515037,  0.99776203,\n",
       "         1.        ,  0.99253787,  0.99925429,  0.99925429,  1.        ,\n",
       "         0.99776203,  1.        ]),\n",
       " 'param_nb__alpha': masked_array(data = [0.1 0.1 0.1 0.1 0.01 0.01 0.01 0.01 0.001 0.001 0.001 0.001],\n",
       "              mask = [False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_tfidf__use_idf': masked_array(data = [True True False False True True False False True True False False],\n",
       "              mask = [False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_vect__ngram_range': masked_array(data = [(1, 1) (1, 2) (1, 1) (1, 2) (1, 1) (1, 2) (1, 1) (1, 2) (1, 1) (1, 2)\n",
       "  (1, 1) (1, 2)],\n",
       "              mask = [False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'nb__alpha': 0.1,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  {'nb__alpha': 0.1, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)},\n",
       "  {'nb__alpha': 0.1, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)},\n",
       "  {'nb__alpha': 0.1, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)},\n",
       "  {'nb__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)},\n",
       "  {'nb__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)},\n",
       "  {'nb__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)},\n",
       "  {'nb__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)},\n",
       "  {'nb__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)},\n",
       "  {'nb__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)},\n",
       "  {'nb__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)},\n",
       "  {'nb__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}],\n",
       " 'rank_test_score': array([ 4,  6,  1,  2,  8, 10,  3,  5, 12, 11,  7,  8], dtype=int32),\n",
       " 'split0_test_score': array([ 0.81431767,  0.80760626,  0.8344519 ,  0.82997763,  0.80089485,\n",
       "         0.80089485,  0.81655481,  0.81879195,  0.7852349 ,  0.78747204,\n",
       "         0.80313199,  0.80089485]),\n",
       " 'split0_train_score': array([ 0.99216125,  1.        ,  0.98656215,  0.99552072,  0.99888018,\n",
       "         1.        ,  0.99216125,  1.        ,  1.        ,  1.        ,\n",
       "         0.99888018,  1.        ]),\n",
       " 'split1_test_score': array([ 0.81655481,  0.80536913,  0.85011186,  0.83221477,  0.79418345,\n",
       "         0.77628635,  0.82102908,  0.8098434 ,  0.76510067,  0.76286353,\n",
       "         0.79642058,  0.77852349]),\n",
       " 'split1_train_score': array([ 0.9944009 ,  0.99888018,  0.98992161,  0.99776036,  0.99888018,\n",
       "         1.        ,  0.9944009 ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99888018,  1.        ]),\n",
       " 'split2_test_score': array([ 0.77130045,  0.76681614,  0.80044843,  0.79820628,  0.73991031,\n",
       "         0.74887892,  0.76681614,  0.76008969,  0.73318386,  0.73991031,\n",
       "         0.74887892,  0.75560538]),\n",
       " 'split2_train_score': array([ 0.99217002,  0.99552573,  0.98322148,  0.99217002,  0.99552573,\n",
       "         1.        ,  0.99105145,  0.99776286,  0.99776286,  1.        ,\n",
       "         0.99552573,  1.        ]),\n",
       " 'std_fit_time': array([ 0.05344825,  0.22817698,  0.08103768,  0.14229889,  0.06774117,\n",
       "         0.15168821,  0.05769988,  0.10017736,  0.0529942 ,  0.07123096,\n",
       "         0.01431095,  0.09777595]),\n",
       " 'std_score_time': array([ 0.01425502,  0.01814319,  0.0188923 ,  0.02524657,  0.05019106,\n",
       "         0.05670544,  0.05020673,  0.05297161,  0.0030775 ,  0.04299396,\n",
       "         0.01706694,  0.08716292]),\n",
       " 'std_test_score': array([ 0.02081809,  0.01871667,  0.02072461,  0.01552557,  0.02729431,\n",
       "         0.02124127,  0.02456054,  0.02581377,  0.0214248 ,  0.01941753,\n",
       "         0.02414039,  0.01848626]),\n",
       " 'std_train_score': array([ 0.00105372,  0.00190104,  0.00273532,  0.00229722,  0.0015813 ,\n",
       "         0.        ,  0.00139309,  0.0010546 ,  0.0010546 ,  0.        ,\n",
       "         0.0015813 ,  0.        ])}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0        0.907054         0.368276         0.800746          0.992911   \n",
      "1        2.979425         0.561748         0.793284          0.998135   \n",
      "2        0.813503         0.358697         0.828358          0.986568   \n",
      "3        3.526064         0.541212         0.820149          0.995150   \n",
      "4        0.841796         0.413933         0.778358          0.997762   \n",
      "5        3.056281         0.647487         0.775373          1.000000   \n",
      "6        0.867871         0.408912         0.801493          0.992538   \n",
      "7        2.990557         0.574054         0.796269          0.999254   \n",
      "8        0.845077         0.359333         0.761194          0.999254   \n",
      "9        2.923411         0.577125         0.763433          1.000000   \n",
      "10       0.790717         0.347324         0.782836          0.997762   \n",
      "11       2.672809         0.473349         0.778358          1.000000   \n",
      "\n",
      "   param_nb__alpha param_tfidf__use_idf param_vect__ngram_range  \\\n",
      "0              0.1                 True                  (1, 1)   \n",
      "1              0.1                 True                  (1, 2)   \n",
      "2              0.1                False                  (1, 1)   \n",
      "3              0.1                False                  (1, 2)   \n",
      "4             0.01                 True                  (1, 1)   \n",
      "5             0.01                 True                  (1, 2)   \n",
      "6             0.01                False                  (1, 1)   \n",
      "7             0.01                False                  (1, 2)   \n",
      "8            0.001                 True                  (1, 1)   \n",
      "9            0.001                 True                  (1, 2)   \n",
      "10           0.001                False                  (1, 1)   \n",
      "11           0.001                False                  (1, 2)   \n",
      "\n",
      "                                               params  rank_test_score  \\\n",
      "0   {'nb__alpha': 0.1, 'vect__ngram_range': (1, 1)...                4   \n",
      "1   {'nb__alpha': 0.1, 'vect__ngram_range': (1, 2)...                6   \n",
      "2   {'nb__alpha': 0.1, 'vect__ngram_range': (1, 1)...                1   \n",
      "3   {'nb__alpha': 0.1, 'vect__ngram_range': (1, 2)...                2   \n",
      "4   {'nb__alpha': 0.01, 'vect__ngram_range': (1, 1...                8   \n",
      "5   {'nb__alpha': 0.01, 'vect__ngram_range': (1, 2...               10   \n",
      "6   {'nb__alpha': 0.01, 'vect__ngram_range': (1, 1...                3   \n",
      "7   {'nb__alpha': 0.01, 'vect__ngram_range': (1, 2...                5   \n",
      "8   {'nb__alpha': 0.001, 'vect__ngram_range': (1, ...               12   \n",
      "9   {'nb__alpha': 0.001, 'vect__ngram_range': (1, ...               11   \n",
      "10  {'nb__alpha': 0.001, 'vect__ngram_range': (1, ...                7   \n",
      "11  {'nb__alpha': 0.001, 'vect__ngram_range': (1, ...                8   \n",
      "\n",
      "    split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0            0.814318            0.992161           0.816555   \n",
      "1            0.807606            1.000000           0.805369   \n",
      "2            0.834452            0.986562           0.850112   \n",
      "3            0.829978            0.995521           0.832215   \n",
      "4            0.800895            0.998880           0.794183   \n",
      "5            0.800895            1.000000           0.776286   \n",
      "6            0.816555            0.992161           0.821029   \n",
      "7            0.818792            1.000000           0.809843   \n",
      "8            0.785235            1.000000           0.765101   \n",
      "9            0.787472            1.000000           0.762864   \n",
      "10           0.803132            0.998880           0.796421   \n",
      "11           0.800895            1.000000           0.778523   \n",
      "\n",
      "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0             0.994401           0.771300            0.992170      0.053448   \n",
      "1             0.998880           0.766816            0.995526      0.228177   \n",
      "2             0.989922           0.800448            0.983221      0.081038   \n",
      "3             0.997760           0.798206            0.992170      0.142299   \n",
      "4             0.998880           0.739910            0.995526      0.067741   \n",
      "5             1.000000           0.748879            1.000000      0.151688   \n",
      "6             0.994401           0.766816            0.991051      0.057700   \n",
      "7             1.000000           0.760090            0.997763      0.100177   \n",
      "8             1.000000           0.733184            0.997763      0.052994   \n",
      "9             1.000000           0.739910            1.000000      0.071231   \n",
      "10            0.998880           0.748879            0.995526      0.014311   \n",
      "11            1.000000           0.755605            1.000000      0.097776   \n",
      "\n",
      "    std_score_time  std_test_score  std_train_score  \n",
      "0         0.014255        0.020818         0.001054  \n",
      "1         0.018143        0.018717         0.001901  \n",
      "2         0.018892        0.020725         0.002735  \n",
      "3         0.025247        0.015526         0.002297  \n",
      "4         0.050191        0.027294         0.001581  \n",
      "5         0.056705        0.021241         0.000000  \n",
      "6         0.050207        0.024561         0.001393  \n",
      "7         0.052972        0.025814         0.001055  \n",
      "8         0.003077        0.021425         0.001055  \n",
      "9         0.042994        0.019418         0.000000  \n",
      "10        0.017067        0.024140         0.001581  \n",
      "11        0.087163        0.018486         0.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(gs_clf.cv_results_)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '007', '00s', '03', '04', '05', '05425', '10', '100', '1000', '100m', '101', '102', '103', '104', '105', '106', '107', '108', '109', '10b', '10s', '10th', '11', '110', '111', '112', '113', '114', '115', '117', '118', '11th', '12', '123', '125', '126', '127', '1272', '128', '129', '1298', '12th', '13', '130', '1305', '131', '132', '133']\n",
      "['zi', 'zidler', 'ziegler', 'ziembicki', 'zigged', 'ziggy', 'zilch', 'zimbabwe', 'zimmely', 'zimmer', 'zimmerly', 'zinger', 'zingers', 'zinnia', 'zip', 'zipped', 'zippel', 'zipper', 'zippers', 'zippy', 'zips', 'ziyi', 'zodiac', 'zoe', 'zombie', 'zombies', 'zombified', 'zone', 'zones', 'zoo', 'zookeeper', 'zoolander', 'zoologist', 'zoom', 'zooming', 'zooms', 'zoot', 'zophres', 'zorg', 'zorro', 'zsigmond', 'zucker', 'zuehlke', 'zuko', 'zukovsky', 'zulu', 'zwick', 'zwigoff', 'zycie', 'zzzzzzz']\n",
      "[[  5.  34.   3. ...,   0.   0.   1.]\n",
      " [  1.  33.   6. ...,   1.   2.   0.]]\n",
      "(2, 34197)\n",
      "[  5.  34.   3. ...,   0.   0.   1.]\n",
      "[  1.  33.   6. ...,   1.   2.   0.]\n",
      "        neg   pos\n",
      "token            \n",
      "00      1.0   5.0\n",
      "000    33.0  34.0\n",
      "007     6.0   3.0\n",
      "00s     0.0   1.0\n",
      "03      0.0   2.0\n",
      "                 neg  pos\n",
      "token                    \n",
      "psyches          1.0  0.0\n",
      "finnegan         0.0  3.0\n",
      "trustworthiness  1.0  0.0\n",
      "patton           2.0  2.0\n",
      "salivate         0.0  1.0\n",
      "[ 665.  675.]\n",
      "                      neg       pos  neg_ratio\n",
      "token                                         \n",
      "psyches          0.002963  0.001504   1.970370\n",
      "finnegan         0.001481  0.006015   0.246296\n",
      "trustworthiness  0.002963  0.001504   1.970370\n",
      "patton           0.004444  0.004511   0.985185\n",
      "salivate         0.001481  0.003008   0.492593\n",
      "                    neg       pos  neg_ratio\n",
      "token                                       \n",
      "mulan          0.142222  0.001504  94.577778\n",
      "flynt          0.118519  0.001504  78.814815\n",
      "sweetback      0.045926  0.001504  30.540741\n",
      "ordell         0.044444  0.001504  29.555556\n",
      "hedwig         0.042963  0.001504  28.570370\n",
      "argento        0.041481  0.001504  27.585185\n",
      "taran          0.040000  0.001504  26.600000\n",
      "pleasantville  0.038519  0.001504  25.614815\n",
      "lambeau        0.038519  0.001504  25.614815\n",
      "fei            0.038519  0.001504  25.614815\n",
      "lebowski       0.075556  0.003008  25.122222\n",
      "chad           0.037037  0.001504  24.629630\n",
      "mallory        0.035556  0.001504  23.644444\n",
      "matilda        0.034074  0.001504  22.659259\n",
      "rounders       0.032593  0.001504  21.674074\n",
      "carver         0.032593  0.001504  21.674074\n",
      "lumumba        0.032593  0.001504  21.674074\n",
      "redford        0.031111  0.001504  20.688889\n",
      "rico           0.031111  0.001504  20.688889\n",
      "cauldron       0.062222  0.003008  20.688889\n",
      "shrek          0.029630  0.001504  19.703704\n",
      "maximus        0.028148  0.001504  18.718519\n",
      "dolores        0.028148  0.001504  18.718519\n",
      "bubby          0.028148  0.001504  18.718519\n",
      "capone         0.026667  0.001504  17.733333\n",
      "gale           0.026667  0.001504  17.733333\n",
      "hen            0.026667  0.001504  17.733333\n",
      "bianca         0.026667  0.001504  17.733333\n",
      "motta          0.026667  0.001504  17.733333\n",
      "damon          0.053333  0.003008  17.733333\n",
      "...                 ...       ...        ...\n",
      "silverman      0.001481  0.021053   0.070370\n",
      "zach           0.001481  0.021053   0.070370\n",
      "bont           0.001481  0.021053   0.070370\n",
      "vikings        0.001481  0.021053   0.070370\n",
      "silverstone    0.001481  0.021053   0.070370\n",
      "sphere         0.001481  0.021053   0.070370\n",
      "dwayne         0.001481  0.021053   0.070370\n",
      "grinch         0.001481  0.022556   0.065679\n",
      "caulder        0.001481  0.022556   0.065679\n",
      "musketeer      0.001481  0.022556   0.065679\n",
      "webb           0.002963  0.046617   0.063560\n",
      "jericho        0.001481  0.024060   0.061574\n",
      "brenner        0.001481  0.024060   0.061574\n",
      "macdonald      0.001481  0.025564   0.057952\n",
      "psychlo        0.001481  0.025564   0.057952\n",
      "bilko          0.001481  0.025564   0.057952\n",
      "sinise         0.001481  0.027068   0.054733\n",
      "eszterhas      0.001481  0.027068   0.054733\n",
      "mandingo       0.001481  0.027068   0.054733\n",
      "kersey         0.001481  0.027068   0.054733\n",
      "bronson        0.001481  0.027068   0.054733\n",
      "alicia         0.002963  0.057143   0.051852\n",
      "schumacher     0.002963  0.061654   0.048058\n",
      "hewitt         0.001481  0.034586   0.042834\n",
      "crawford       0.001481  0.036090   0.041049\n",
      "freddie        0.001481  0.040602   0.036488\n",
      "jakob          0.001481  0.042105   0.035185\n",
      "prinze         0.001481  0.042105   0.035185\n",
      "seagal         0.002963  0.094737   0.031276\n",
      "nbsp           0.001481  0.088722   0.016698\n",
      "\n",
      "[34197 rows x 3 columns]\n",
      "1.0544946957\n"
     ]
    }
   ],
   "source": [
    "##TODO : neg are neg ? pos are pos ?\n",
    "nb = MultinomialNB()\n",
    "# store the vocabulary of X_train\n",
    "vect = CountVectorizer().fit(X_train)\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)\n",
    "# examine the first 50 tokens\n",
    "print(X_train_tokens[0:50])\n",
    "# examine the last 50 tokens\n",
    "print(X_train_tokens[-50:])\n",
    "# Naive Bayes counts the number of times each token appears in each class\n",
    "# trailing underscore is scikit convention for attributes that are learned during model fitting\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "nb = nb.fit(X_train_dtm, y_train)\n",
    "print(nb.feature_count_)\n",
    "# rows represent classes, columns represent tokens\n",
    "print(nb.feature_count_.shape)\n",
    "# number of times each token appears across all HAM messages\n",
    "pos_token_count = nb.feature_count_[0, :]\n",
    "print(pos_token_count)\n",
    "# number of times each token appears across all SPAM messages\n",
    "neg_token_count = nb.feature_count_[1, :]\n",
    "print(neg_token_count)\n",
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame({\"token\":X_train_tokens, \"pos\":pos_token_count, \"neg\":neg_token_count}).set_index(\"token\")\n",
    "print(tokens.head())\n",
    "# examine 5 random DataFrame rows\n",
    "print(tokens.sample(5, random_state=6))\n",
    "# Naive Bayes counts the number of observations in each class\n",
    "print(nb.class_count_)\n",
    "# add 1 to ham and spam counts to avoid 0 probabilities\n",
    "tokens['pos'] = tokens['pos'] + 1\n",
    "tokens['neg'] = tokens['neg'] + 1\n",
    "tokens.sample(5, random_state=6)\n",
    "# convert the ham and spam counts into frequencies\n",
    "tokens['pos'] = tokens['pos'] / nb.class_count_[0]\n",
    "tokens['neg'] = tokens['neg'] / nb.class_count_[1]\n",
    "tokens.sample(5, random_state=6)\n",
    "# calculate the ratio of neg-to-pos for each token\n",
    "tokens['neg_ratio'] = tokens['neg'] / tokens['pos']\n",
    "print(tokens.sample(5, random_state=6))\n",
    "# examine the DataFrame sorted by spam_ratio\n",
    "# note: use sort() instead of sort_values() for pandas 0.16.2 and earlier\n",
    "print(tokens.sort_values('neg_ratio', ascending=False))\n",
    "# look up the spam_ratio for a given token\n",
    "print(tokens.loc[\"good\", \"neg_ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same parameter to vectorize data in order to compare to precedent methods\n",
    "# Logistic regression\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range =(1,2), max_df =0.7, min_df=2)),\n",
    "                     ('nb', LogisticRegression()),\n",
    "                    ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "y_pred_class = text_clf.predict(X_test)\n",
    "\n",
    "y_pred_prob = text_clf.predict(X_test)\n",
    "\n",
    "metrics.confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred_class,\n",
    "    target_names=[\"pos\",\"neg\"]))\n",
    "metrics.accuracy_score(y_test, y_pred_class)\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TfidTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5aced182d9df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mX_train_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_dtm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mX_train_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mX_test_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_dtm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#Train logistic regression with TF representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TfidTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "# With TF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vect = CountVectorizer(stop_words='english', ngram_range =(1,2), max_df =0.7, min_df=2)\n",
    "\n",
    "# combine fit and transform into a single step\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "#look at the training data\n",
    "pd.DataFrame(X_train_dtm.toarray(), columns=vect.get_feature_names())\n",
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm\n",
    "\n",
    "#Compute TF\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "X_train_tf = tf_transformer.fit_transform(X_train_dtm)\n",
    "X_train_tf.shape\n",
    "X_test_tf = TfidfTransformer(use_idf=False).fit_transform(X_train_dtm)\n",
    "#Train logistic regression with TF representation\n",
    "lr = LogisticRegression().fit(X_train_tf, y_train)\n",
    "\n",
    "y_pred_class = lr.predict(X_test_tf)\n",
    "\n",
    "y_pred_prob = lr.predict_proba(X_test_tf)\n",
    "\n",
    "metrics.confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred_class,\n",
    "    target_names=[\"pos\",\"neg\"]))\n",
    "metrics.accuracy_score(y_test, y_pred_class)\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(660, 50456)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-7c07a568b88d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_class_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_class_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scikitplot/metrics.py\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(y_true, y_pred, labels, true_labels, pred_labels, title, normalize, hide_zeros, hide_counts, x_tick_rotation, ax, figsize, cmap, title_fontsize, text_fontsize)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 230\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 0]"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.colors' has no attribute 'to_rgba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# determine if a background is needed for legibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m_is_transparent\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.colors' has no attribute 'to_rgba'"
     ]
    }
   ],
   "source": [
    "\n",
    "### Computing TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_dtm)\n",
    "X_train_tfidf.shape\n",
    "\n",
    "nb_tfidf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_dtm)\n",
    "print(X_test_tfidf.shape)\n",
    "y_pred_class_tfidf = nb_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "metrics.accuracy_score(y_test, y_pred_class_tfidf)\n",
    "\n",
    "plot_confusion_matrix(metrics.confusion_matrix(y_test, y_pred_class_tfidf),[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE STRING KERNELS : not done until now in others group and suggested at the very end of the teacher's notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
