{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>neg</td>\n",
       "      <td>if there were a subject just screaming to be m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>pos</td>\n",
       "      <td>\" rebel without a cause \" is such an importan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>neg</td>\n",
       "      <td>wolfgang petersen's latest , the perfect storm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>pos</td>\n",
       "      <td>the keen wisdom of an elderly bank robber , th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>pos</td>\n",
       "      <td>the happy bastard's 30-second review : \\nameri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  label_num\n",
       "1390   neg  if there were a subject just screaming to be m...          0\n",
       "712    pos   \" rebel without a cause \" is such an importan...          1\n",
       "1026   neg  wolfgang petersen's latest , the perfect storm...          0\n",
       "542    pos  the keen wisdom of an elderly bank robber , th...          1\n",
       "401    pos  the happy bastard's 30-second review : \\nameri...          1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all files path\n",
    "posFiles = glob('review_polarity/txt_sentoken/pos/*')\n",
    "negFiles = glob('review_polarity/txt_sentoken/neg/*')\n",
    "#read text files\n",
    "posReviews = np.array([open(f).read() for f in posFiles])\n",
    "negReviews = np.array([open(f).read() for f in negFiles])\n",
    "#use pandas to label and mix the data\n",
    "polarity_files_df = pd.DataFrame({'pos':posReviews,'neg':negReviews})\n",
    "polarity_files_df = pd.melt(polarity_files_df, value_vars=['pos','neg'],value_name=\"text\",var_name=\"label\")\n",
    "polarity_files_df[\"label_num\"] = polarity_files_df.label.map({\"neg\":0, \"pos\":1})\n",
    "polarity_files_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1340,)\n",
      "(660,)\n",
      "(1340,)\n",
      "(660,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(polarity_files_df.text, polarity_files_df.label_num, test_size=0.33, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.82      0.80      0.81       335\n",
      "         neg       0.80      0.82      0.81       325\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       660\n",
      "   macro avg       0.81      0.81      0.81       660\n",
      "weighted avg       0.81      0.81      0.81       660\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.80909090909090908"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove English stop words\n",
    "# include 1-grams and 2-grams (if 3-grams : seems not better because of the length of the vector)\n",
    "# ignore terms that appear in more than 70% of the documents (intuitively meaningful, it is indeed the best multiple of 10% to have a good score )\n",
    "# only keep terms that appear in at least 2 documents\n",
    "\n",
    "# TODO : remove 'not' etc. from stopwords to not remove 'not' from sentences like 'this film is not bad'\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range =(1,2), max_df =0.7, min_df=2)),\n",
    "                     ('nb', MultinomialNB()),\n",
    "                    ])\n",
    "\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "y_pred = text_clf.predict(X_test)\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "# à vérifier : pos et neg sont biens les pos et neg\n",
    "print(metrics.classification_report(y_test, y_pred,\n",
    "    target_names=[\"pos\",\"neg\"]))\n",
    "metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "#plt.figure()\n",
    "#plot_confusion_matrix(cnf_matrix, classes=['pos','neg'],\n",
    "#                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "#plt.figure()\n",
    "#plot_confusion_matrix(cnf_matrix, classes=['pos','neg'], normalize=True,\n",
    "#                      title='Normalized confusion matrix')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'nb': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " 'nb__alpha': 1.0,\n",
       " 'nb__class_prior': None,\n",
       " 'nb__fit_prior': True,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=0.7, max_features=None, min_df=2,\n",
       "           ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "           strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=None, vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=0.7, max_features=None, min_df=2,\n",
       "         ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=None, vocabulary=None),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 0.7,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 2,\n",
       " 'vect__ngram_range': (1, 3),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': 'english',\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': None,\n",
       " 'vect__vocabulary': None}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test a range of hyperparameters\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range =(1,3), max_df =0.7, min_df=2)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('nb', MultinomialNB()),\n",
    "                    ])\n",
    "\n",
    "text_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#TO ADAPT depending on what text_clf.get_params() displays\n",
    "#parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#              'tfidf__use_idf': (True, False),\n",
    "#              'nb__alpha': (1e-2, 1e-3),\n",
    "#}\n",
    "#gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "y_pred = gs_clf.predict(X_test)\n",
    "\n",
    "gs_clf.best_score_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TO ADAPT : examine most frequent words assigned to pos and neg reviews\n",
    "\n",
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)\n",
    "# examine the first 50 tokens\n",
    "print(X_train_tokens[0:50])\n",
    "# examine the last 50 tokens\n",
    "print(X_train_tokens[-50:])\n",
    "# Naive Bayes counts the number of times each token appears in each class\n",
    "# trailing underscore is scikit convention for attributes that are learned during model fitting\n",
    "nb.feature_count_\n",
    "# rows represent classes, columns represent tokens\n",
    "nb.feature_count_.shape\n",
    "# number of times each token appears across all HAM messages\n",
    "ham_token_count = nb.feature_count_[0, :]\n",
    "ham_token_count\n",
    "# number of times each token appears across all SPAM messages\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "spam_token_count\n",
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame({\"token\":X_train_tokens, \"ham\":ham_token_count, \"spam\":spam_token_count}).set_index(\"token\")\n",
    "tokens.head()\n",
    "# examine 5 random DataFrame rows\n",
    "tokens.sample(5, random_state=6)\n",
    "# Naive Bayes counts the number of observations in each class\n",
    "nb.class_count_\n",
    "# add 1 to ham and spam counts to avoid 0 probabilities\n",
    "tokens['ham'] = tokens['ham'] + 1\n",
    "tokens['spam'] = tokens['spam'] + 1\n",
    "tokens.sample(5, random_state=6)\n",
    "# convert the ham and spam counts into frequencies\n",
    "tokens['ham'] = tokens['ham'] / nb.class_count_[0]\n",
    "tokens['spam'] = tokens['spam'] / nb.class_count_[1]\n",
    "tokens.sample(5, random_state=6)\n",
    "# calculate the ratio of spam-to-ham for each token\n",
    "tokens['spam_ratio'] = tokens['spam'] / tokens['ham']\n",
    "tokens.sample(5, random_state=6)\n",
    "# examine the DataFrame sorted by spam_ratio\n",
    "# note: use sort() instead of sort_values() for pandas 0.16.2 and earlier\n",
    "tokens.sort_values('spam_ratio', ascending=False)\n",
    "# look up the spam_ratio for a given token\n",
    "tokens.loc[\"dating\", \"spam_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range =(1,3), max_df =0.7, min_df=2)),\n",
    "                     ('nb', LogisticRegression()),\n",
    "                    ])\n",
    "\n",
    "y_pred_class = text_clf.predict(X_test)\n",
    "\n",
    "y_pred_prob = text_clf.predict(X_test)\n",
    "\n",
    "metrics.confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred_class,\n",
    "    target_names=[\"pos\",\"neg\"]))\n",
    "metrics.accuracy_score(y_test, y_pred_class)\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With TF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('nb', LogisticRegression()),\n",
    "                    ])\n",
    "\n",
    "X_train_tf = text_clf.fit_transform(X_train)\n",
    "X_train_tf.shape\n",
    "\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "X_test_tf = tfidf_transformer.transform(X_test)\n",
    "\n",
    "y_pred_class = text_clf.predict(X_test_tf)\n",
    "\n",
    "y_pred_prob = text_clf.predict(X_test_tf)\n",
    "\n",
    "metrics.confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred_class,\n",
    "    target_names=[\"pos\",\"neg\"]))\n",
    "metrics.accuracy_score(y_test, y_pred_class)\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                     ('nb', LogisticRegression()),\n",
    "                    ])\n",
    "\n",
    "X_train_tfidf = text_clf.fit_transform(X_train)\n",
    "X_train_tfidf.shape\n",
    "\n",
    "\n",
    "tf_transformer = TfidfTransformer()\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test)\n",
    "\n",
    "y_pred_class = text_clf.predict(X_test_tfidf)\n",
    "\n",
    "y_pred_prob = text_clf.predict(X_test_tfidf)\n",
    "\n",
    "metrics.confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred_class,\n",
    "    target_names=[\"pos\",\"neg\"]))\n",
    "metrics.accuracy_score(y_test, y_pred_class)\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE STRING KERNELS : not done until now in others group and suggested at the very end of the teacher's notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
